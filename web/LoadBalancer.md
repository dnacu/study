# Load Balancer

## 로드밸런서란

하나의 서버로는 성능이 아무리 좋아도 수많은 트래픽을 감당해 낼 수 없다. 이에 기업들은 서버를 추가로 구매하고, 여러 서버에 동일한 데이터를 저장하여 트래픽을 효과적으로 분산한다.

단순히 다수의 서버를 구축하고, 운영한다고 해서 모든 클라이언트의 요청에 일관성 있게 응답해줄 수 없다. 수많은 트래픽을 여러 서버로 분산해주는 기술이 필요하다. 그렇지 않으면 한 곳의 서버에 트래픽이 몰려 병목 현상이 생길 것이기 때문이다. 이를 위한 기술이 바로 **로드밸런싱**이다.

로드밸런서는 서버에 가해지는 부하를 분산해주는 장치 또는 기술을 통칭한다. 클라이언트와 서버 풀 사이에 위치하여 특정 서버로 부하가 집중되지 않도록 트래픽을 관리하여 최적의 퍼포먼스를 보일 수 있도록 도와준다.

## 로드밸런싱의 필요성

로드밸런싱은 여러 대의 서버를 두고 서비스를 제공하는 분산 처리 시스템에서 필요한 기술이다.

서비스 제공 초기에는 적은 클라이언트만 대응하면 되기 떄문에 서버 한 대로 처리가 가능하지만, 사업의 규모가 확장됨에 따라 클라이언트 수가 늘어나고, 기존 한 대의 서버로는 정상적인 서비스가 불가능하게 된다. 이 때 증가한 트래픽에 대처할 수 있는 방법은 크게 두 가지이다.

### Scale up, Scale out

`Scale up`은 서버 자체의 성능을 확장하는 것을 의미하고, `Scale out`은 기존과 비슷하거나 낮은 성능의 서버를 증설하여 두 대 이상 운영하는 것을 의미한다.

`Scale up`방식에는 트래픽 처리의 한계가 존재하고, 하나의 서버로만 동작하기 때문에 이상이 생기면 전체 서비스가 다운되는 단점 등이 있다. 따라서 트래픽이 굉장히 커진다면 `Scale out` 방식을 채택하게 될 텐데, 이 때 로드밸런서가 반드시 필요하다.

## 로드밸런싱 알고리즘

**라운드로빈 방식**  
서버에 들어온 요청을 순서대로 돌아가며 배정한다. 여러 서버가 동일한 스펙일때 좋다.

**가중 라운드로빈 방식**  
각 서버마다 가중치를 매기고 가중치가 높은 서버에 우선적으로 트래픽을 분배한다. 좋은 스펙의 서버에 가중치를 높게 두는 방식으로 활용 가능하다.

**IP 해시 방식**  
클라이언트의 IP주소를 특정 서버로 매핑한다. 사용자가 항상 동일한 서버로 연결되는 것을 보장한다.

**최소 연결 방식**  
요청이 들어온 시점에 가장 적은 커넥션을 가진 서버에 우선적으로 분배한다.

**최소 리스폰타임**  
서버의 현재 커넥션 상태와 응답시간을 모두 고려하여 트래픽을 배분한다. 적은 연결과 짧은 응답시간을 보이는 서버에 우선적으로 트래픽 배분.

## 로드밸런서의 종류

### L4 로드밸런서

네트워크 계층(IP) 혹은 트랜스포트 계층(TCP/UDP)의 정보를 바탕으로 트래픽을 분산한다. IP주소, 포트번호, MAC주소, 전송 프로토콜에 따라 트래픽을 나누는 것이 가능하다.

### L7 로드밸런서

어플리케이션 계층에서 트래픽을 분산하기 때문에 HTTP 헤더, 쿠키 등과 같은 사용자 요청을 기준으로 삼을 수 있다. 쉽게 말해 패킷의 내용을 확인하고, 그 내용에 따라 분산이 가능하다는 것이다. 따라서 URL이나 HTTP헤더의 쿠키값에 따라 분산하는 등 클라이언트 요청을 보다 세분화하여 서버에 전달할 수 있다.

![image](https://user-images.githubusercontent.com/36905916/96771935-5786ef00-141d-11eb-8f2c-4a5ef1e49a69.png)
